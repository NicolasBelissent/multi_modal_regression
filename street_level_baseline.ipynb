{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline on Street Level images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import time\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_dataset(dataset, val_split=0.3):\n",
    "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
    "    datasets = {}\n",
    "    datasets['train'] = Subset(dataset, train_idx)\n",
    "    datasets['val'] = Subset(dataset, val_idx)\n",
    "    return datasets\n",
    "\n",
    "# define the path to the images\n",
    "path_to_data = 'street_level_images/'\n",
    "\n",
    "#defining a built-in tranform function\n",
    "transform = transforms.Compose([transforms.Resize(224),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "# load the dataset\n",
    "dataset = datasets.ImageFolder(path_to_data, transform=transform)\n",
    "split_dataset = train_val_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining dataloader\n",
    "batch_size = 128 # taken from baseline\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(split_dataset[x], batch_size=batch_size, shuffle=True, num_workers=2) for x in ['train', 'val']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import torch\\nimport pandas as pd\\nimport os'); }\n    ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get folder names\n",
    "locations = [name for name in os.listdir(path_to_data)]\n",
    "\n",
    "# load features dataframe\n",
    "features_df = pd.read_csv('dhs_final_labels.csv')\n",
    "\n",
    "# make a target dict\n",
    "target_dict = {}\n",
    "test_keys = list(features_df['DHSID_EA'])\n",
    "test_values = list(features_df['sanitation_index'])\n",
    "\n",
    "target_dict = {test_keys[i]: test_values[i] for i in range(len(test_keys))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def train_model(model, dataloaders, locations, target_dict,  criterion, optimizer,num_epochs=20, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            with tqdm(dataloaders[phase],unit = 'batch') as tepoch:\n",
    "              # Iterate over data.\n",
    "              for inputs, labels in tepoch:\n",
    "            \n",
    "                  # get DHSID_EA id for alll labels\n",
    "                  lb_ids = [locations[id] for id in labels]\n",
    "                  # get feature values\n",
    "                  labels = [target_dict[lb_id] for lb_id in lb_ids]\n",
    "\n",
    "                  labels = torch.Tensor(labels)\n",
    "\n",
    "                  #inputs = inputs.to(device)\n",
    "                  #labels = labels.to(device)\n",
    "                  print('labels',labels)\n",
    "\n",
    "                  # zero the parameter gradients\n",
    "                  optimizer.zero_grad()\n",
    "\n",
    "                  # forward\n",
    "                  # track history if only in train\n",
    "                  with torch.set_grad_enabled(phase == 'train'):\n",
    "                      # Get model outputs and calculate loss\n",
    "                      # Special case for inception because in training it has an auxiliary output. In train\n",
    "                      #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                      #   but in testing we only consider the final output.\n",
    "                      \n",
    "                    outputs = model(inputs)\n",
    "                    print('outputs', outputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    print('loss', loss)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    \n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                      \n",
    "\n",
    "                  # statistics\n",
    "                  running_loss += loss.item() * inputs.size(0)\n",
    "                  #getCategoricalAccuracy(preds, labels.data, class_dict)\n",
    "                  running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "              epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "              epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "              print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "              # deep copy the model\n",
    "              if phase == 'val' and epoch_acc > best_acc:\n",
    "                  best_acc = epoch_acc\n",
    "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
    "              if phase == 'val':\n",
    "                  val_acc_history.append(epoch_acc)\n",
    "              if phase == 'train':\n",
    "                  train_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, train_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the loss fxn\n",
    "import time\n",
    "import copy\n",
    "criterion = nn.MSELoss()\n",
    "epoch = 50 # from baseline\n",
    "lr = 0.01 # from baseline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nbelisse\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nbelisse\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n",
      "Epoch 0/49\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/140 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels tensor([3.0000, 3.4091, 5.0000, 3.3182, 5.0000, 3.0000, 4.9000, 3.2500, 5.0000,\n",
      "        3.0909, 5.0000, 5.0000, 5.0000, 4.7273, 3.0000, 5.0000, 3.0909, 3.6818,\n",
      "        3.7143, 5.0000, 3.0000, 3.0000, 3.2857, 5.0000, 5.0000, 4.1818, 3.9545,\n",
      "        3.2857, 3.3182, 5.0000, 3.4091, 3.3182, 5.0000, 3.2727, 3.0000, 3.0000,\n",
      "        5.0000, 3.0000, 5.0000, 3.0000, 5.0000, 3.0476, 3.0476, 5.0000, 5.0000,\n",
      "        5.0000, 3.0000, 3.9091, 5.0000, 5.0000, 3.2857, 3.0833, 3.0000, 3.0000,\n",
      "        5.0000, 3.2857, 3.0909, 5.0000, 3.7727, 3.7273, 5.0000, 3.4091, 3.0455,\n",
      "        5.0000, 3.0000, 3.0000, 3.3810, 4.0000, 3.2609, 3.0455, 3.0000, 3.4500,\n",
      "        5.0000, 3.0000, 5.0000, 4.3333, 3.0000, 4.2727, 5.0000, 5.0000, 3.8000,\n",
      "        3.7143, 3.4286, 5.0000, 3.3810, 3.0000, 3.0000, 5.0000, 5.0000, 4.0909,\n",
      "        5.0000, 3.0000, 3.2273, 5.0000, 3.0000, 3.2727, 3.0476, 5.0000, 3.2273,\n",
      "        4.1364, 5.0000, 3.1429, 3.0000, 4.0909, 3.0000, 5.0000, 4.1429, 3.7273,\n",
      "        3.3810, 5.0000, 3.4000, 3.0000, 5.0000, 5.0000, 3.2857, 4.7619, 3.2857,\n",
      "        3.2857, 3.9545, 3.2500, 5.0000, 3.0000, 5.0000, 2.9545, 3.0000, 4.4762,\n",
      "        3.6364, 5.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nbelisse\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  1%|          | 1/140 [00:12<30:06, 13.00s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs tensor([[ 2.5766e-01],\n",
      "        [ 7.5586e-01],\n",
      "        [ 7.0540e-01],\n",
      "        [ 6.3699e-01],\n",
      "        [ 4.2074e-01],\n",
      "        [ 3.7490e-01],\n",
      "        [ 3.7101e-01],\n",
      "        [ 1.2927e+00],\n",
      "        [ 4.1902e-01],\n",
      "        [ 7.7523e-01],\n",
      "        [ 2.1131e-01],\n",
      "        [ 8.5267e-01],\n",
      "        [ 6.3052e-01],\n",
      "        [ 5.4730e-01],\n",
      "        [ 3.2886e-01],\n",
      "        [ 1.8834e-01],\n",
      "        [ 2.7206e-01],\n",
      "        [ 5.0718e-01],\n",
      "        [ 3.4291e-01],\n",
      "        [ 1.5025e+00],\n",
      "        [ 6.1437e-02],\n",
      "        [-6.9988e-04],\n",
      "        [ 4.7427e-01],\n",
      "        [ 9.3374e-01],\n",
      "        [-6.9035e-02],\n",
      "        [ 3.4345e-01],\n",
      "        [ 7.5014e-01],\n",
      "        [ 5.1264e-01],\n",
      "        [ 8.5427e-01],\n",
      "        [ 9.6541e-01],\n",
      "        [ 6.8143e-01],\n",
      "        [-2.0386e-01],\n",
      "        [ 1.2480e+00],\n",
      "        [ 6.3649e-03],\n",
      "        [ 5.7183e-01],\n",
      "        [ 1.2928e+00],\n",
      "        [ 7.8644e-01],\n",
      "        [ 2.5028e-01],\n",
      "        [ 6.7750e-02],\n",
      "        [ 7.9242e-01],\n",
      "        [-1.7738e-01],\n",
      "        [ 4.5842e-01],\n",
      "        [ 6.8529e-01],\n",
      "        [ 1.0002e+00],\n",
      "        [-6.1795e-01],\n",
      "        [ 6.1287e-01],\n",
      "        [ 2.7668e-01],\n",
      "        [ 8.3685e-01],\n",
      "        [ 4.2351e-01],\n",
      "        [ 3.3869e-01],\n",
      "        [-7.4098e-02],\n",
      "        [ 2.7793e-01],\n",
      "        [ 6.3676e-01],\n",
      "        [ 4.3957e-01],\n",
      "        [ 6.1340e-01],\n",
      "        [-3.6073e-01],\n",
      "        [ 5.8020e-01],\n",
      "        [ 3.1718e-02],\n",
      "        [ 5.3971e-01],\n",
      "        [ 1.0535e+00],\n",
      "        [ 2.9619e-01],\n",
      "        [ 5.5399e-01],\n",
      "        [ 2.9010e-01],\n",
      "        [ 5.0891e-01],\n",
      "        [ 2.8020e-01],\n",
      "        [ 5.5712e-01],\n",
      "        [ 2.7583e-01],\n",
      "        [-3.5047e-01],\n",
      "        [ 4.9854e-01],\n",
      "        [ 1.2385e+00],\n",
      "        [ 2.5627e-01],\n",
      "        [ 3.9636e-01],\n",
      "        [ 6.0276e-01],\n",
      "        [ 3.4693e-01],\n",
      "        [ 5.1862e-01],\n",
      "        [-2.4098e-01],\n",
      "        [-5.6131e-02],\n",
      "        [ 1.3517e-01],\n",
      "        [ 2.1463e-01],\n",
      "        [ 6.8074e-01],\n",
      "        [ 4.8928e-01],\n",
      "        [ 7.3148e-01],\n",
      "        [ 2.1748e-01],\n",
      "        [ 6.6032e-01],\n",
      "        [ 5.9538e-01],\n",
      "        [ 3.0304e-01],\n",
      "        [ 5.5598e-01],\n",
      "        [ 3.2118e-01],\n",
      "        [ 9.2741e-01],\n",
      "        [ 2.5815e-01],\n",
      "        [ 2.1662e-01],\n",
      "        [ 1.3310e+00],\n",
      "        [ 8.5953e-02],\n",
      "        [ 7.5429e-01],\n",
      "        [-2.8400e-01],\n",
      "        [-1.4873e-01],\n",
      "        [ 1.7310e-01],\n",
      "        [ 3.7129e-01],\n",
      "        [-2.5179e-01],\n",
      "        [-2.5871e-01],\n",
      "        [ 6.6556e-01],\n",
      "        [ 4.2135e-01],\n",
      "        [-4.5714e-02],\n",
      "        [ 2.7193e-01],\n",
      "        [ 1.3246e-02],\n",
      "        [ 3.5981e-02],\n",
      "        [ 6.1605e-01],\n",
      "        [ 4.9571e-01],\n",
      "        [ 3.6912e-01],\n",
      "        [ 2.7861e-01],\n",
      "        [ 4.5541e-01],\n",
      "        [ 9.5663e-01],\n",
      "        [-3.3745e-02],\n",
      "        [ 2.2870e-01],\n",
      "        [ 1.8027e-01],\n",
      "        [ 8.5900e-01],\n",
      "        [ 9.4629e-01],\n",
      "        [ 7.1430e-01],\n",
      "        [-3.7002e-01],\n",
      "        [ 2.1075e-01],\n",
      "        [-5.9089e-02],\n",
      "        [ 2.7890e-01],\n",
      "        [ 1.9803e-01],\n",
      "        [-3.0429e-01],\n",
      "        [ 1.5915e-01],\n",
      "        [ 7.2870e-01],\n",
      "        [ 2.4597e-01],\n",
      "        [-5.7055e-02]], grad_fn=<AddmmBackward0>)\n",
      "loss tensor(13.2307, grad_fn=<MseLossBackward0>)\n",
      "labels tensor([3.0000, 3.2857, 5.0000, 3.0952, 3.3000, 3.0000, 4.4286, 3.0000, 3.6364,\n",
      "        5.0000, 3.9545, 3.0000, 3.0455, 3.2609, 5.0000, 3.3000, 3.0000, 3.3810,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 3.0000, 3.0000, 3.0000, 5.0000, 4.1429,\n",
      "        3.0000, 3.4091, 3.0000, 5.0000, 5.0000, 3.0476, 3.4091, 3.0000, 4.2727,\n",
      "        4.6364, 3.2273, 5.0000, 3.0476, 3.4545, 3.0000, 2.9474, 5.0000, 3.0952,\n",
      "        5.0000, 3.4000, 3.2273, 3.2273, 5.0000, 5.0000, 3.1429, 5.0000, 4.4286,\n",
      "        3.1429, 3.2609, 5.0000, 3.7273, 3.3182, 3.0000, 3.0000, 3.4500, 3.0476,\n",
      "        5.0000, 3.4000, 3.3182, 5.0000, 3.9545, 3.8000, 5.0000, 3.3182, 4.0000,\n",
      "        2.9545, 3.0000, 2.9545, 5.0000, 3.0000, 3.3182, 3.0000, 3.0476, 3.0000,\n",
      "        5.0000, 5.0000, 5.0000, 3.0000, 3.0000, 3.0000, 3.2500, 5.0000, 3.0000,\n",
      "        4.1364, 5.0000, 3.3000, 3.0476, 4.4286, 3.0455, 5.0000, 5.0000, 5.0000,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 3.0909, 5.0000, 3.0000, 3.6364, 5.0000,\n",
      "        5.0000, 3.7727, 5.0000, 5.0000, 3.9545, 3.0000, 2.5909, 2.9524, 3.2609,\n",
      "        5.0000, 5.0000, 3.3182, 5.0000, 3.4091, 5.0000, 3.0000, 5.0000, 3.8182,\n",
      "        3.1905, 3.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/140 [00:19<21:13,  9.23s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs tensor([[ 0.3222],\n",
      "        [ 0.3345],\n",
      "        [ 0.4716],\n",
      "        [-0.1495],\n",
      "        [ 0.7715],\n",
      "        [-0.0568],\n",
      "        [-0.0623],\n",
      "        [ 0.3178],\n",
      "        [ 0.2662],\n",
      "        [ 0.4389],\n",
      "        [-0.1904],\n",
      "        [ 0.8488],\n",
      "        [ 0.4873],\n",
      "        [ 0.2125],\n",
      "        [ 0.6168],\n",
      "        [ 0.2680],\n",
      "        [ 0.4893],\n",
      "        [ 0.7729],\n",
      "        [ 0.9973],\n",
      "        [ 0.3664],\n",
      "        [ 0.3576],\n",
      "        [ 0.7672],\n",
      "        [ 0.8413],\n",
      "        [ 0.6559],\n",
      "        [ 1.0265],\n",
      "        [-0.0451],\n",
      "        [ 0.2979],\n",
      "        [ 0.1500],\n",
      "        [ 0.4571],\n",
      "        [ 0.0586],\n",
      "        [ 0.2225],\n",
      "        [-0.0933],\n",
      "        [ 0.3637],\n",
      "        [ 1.2457],\n",
      "        [ 0.7144],\n",
      "        [ 0.1654],\n",
      "        [ 0.7971],\n",
      "        [ 0.2538],\n",
      "        [ 0.4306],\n",
      "        [ 0.3204],\n",
      "        [ 0.1105],\n",
      "        [-0.0346],\n",
      "        [ 0.5784],\n",
      "        [ 0.3037],\n",
      "        [ 0.4526],\n",
      "        [ 0.7480],\n",
      "        [ 0.3622],\n",
      "        [ 0.3555],\n",
      "        [ 0.2421],\n",
      "        [ 0.7873],\n",
      "        [-0.3249],\n",
      "        [ 0.0889],\n",
      "        [ 0.7955],\n",
      "        [ 0.2924],\n",
      "        [ 0.5973],\n",
      "        [ 0.6007],\n",
      "        [ 1.2581],\n",
      "        [ 0.1549],\n",
      "        [ 0.1402],\n",
      "        [-0.1807],\n",
      "        [ 0.3980],\n",
      "        [ 0.3941],\n",
      "        [ 0.3448],\n",
      "        [ 1.1794],\n",
      "        [ 0.4032],\n",
      "        [ 0.4764],\n",
      "        [ 1.2502],\n",
      "        [ 0.7395],\n",
      "        [-0.0173],\n",
      "        [ 0.6372],\n",
      "        [ 0.5647],\n",
      "        [ 0.3622],\n",
      "        [-0.0284],\n",
      "        [ 1.0155],\n",
      "        [ 0.2757],\n",
      "        [ 1.0517],\n",
      "        [-0.0190],\n",
      "        [ 0.3275],\n",
      "        [ 0.5707],\n",
      "        [ 0.0844],\n",
      "        [ 0.4924],\n",
      "        [-0.0423],\n",
      "        [-0.1252],\n",
      "        [ 1.1567],\n",
      "        [ 0.5352],\n",
      "        [-0.0179],\n",
      "        [ 0.3532],\n",
      "        [ 0.5512],\n",
      "        [ 0.2513],\n",
      "        [ 0.3642],\n",
      "        [ 0.9221],\n",
      "        [ 0.3609],\n",
      "        [-0.4654],\n",
      "        [ 0.2822],\n",
      "        [ 1.4961],\n",
      "        [ 0.2925],\n",
      "        [ 0.9583],\n",
      "        [ 0.7700],\n",
      "        [ 0.3045],\n",
      "        [ 0.7778],\n",
      "        [ 0.9197],\n",
      "        [ 0.0497],\n",
      "        [ 0.8832],\n",
      "        [ 0.1868],\n",
      "        [ 0.3414],\n",
      "        [ 0.1414],\n",
      "        [ 0.4498],\n",
      "        [ 0.8878],\n",
      "        [ 0.3106],\n",
      "        [ 0.7229],\n",
      "        [ 0.2348],\n",
      "        [ 0.6402],\n",
      "        [ 0.8224],\n",
      "        [ 0.0080],\n",
      "        [ 0.1108],\n",
      "        [ 0.7427],\n",
      "        [-0.4304],\n",
      "        [ 0.5372],\n",
      "        [ 0.2488],\n",
      "        [ 0.4657],\n",
      "        [ 0.6379],\n",
      "        [ 0.9064],\n",
      "        [ 0.3194],\n",
      "        [ 0.7339],\n",
      "        [ 0.6728],\n",
      "        [ 0.8281],\n",
      "        [ 0.7497],\n",
      "        [ 0.4596]], grad_fn=<AddmmBackward0>)\n",
      "loss tensor(12.6762, grad_fn=<MseLossBackward0>)\n",
      "labels tensor([3.0000, 5.0000, 3.4545, 5.0000, 5.0000, 4.0909, 3.1905, 3.6364, 5.0000,\n",
      "        3.0000, 3.0000, 3.0000, 3.4545, 5.0000, 5.0000, 3.1905, 3.2273, 3.6364,\n",
      "        3.0000, 3.0455, 5.0000, 5.0000, 3.6364, 3.0000, 5.0000, 3.0000, 3.1905,\n",
      "        3.0000, 5.0000, 5.0000, 4.5000, 5.0000, 3.0000, 3.0000, 3.0833, 5.0000,\n",
      "        3.2609, 4.5000, 5.0000, 3.3182, 3.0000, 3.3182, 5.0000, 5.0000, 3.3182,\n",
      "        3.7727, 3.6364, 3.9545, 3.7143, 3.3182, 4.9048, 3.0476, 3.2727, 3.0000,\n",
      "        3.0909, 3.2727, 3.8182, 5.0000, 5.0000, 3.0455, 3.4762, 5.0000, 3.2727,\n",
      "        5.0000, 3.0000, 3.0000, 3.0000, 5.0000, 3.7727, 5.0000, 4.2273, 3.2857,\n",
      "        5.0000, 2.9545, 3.0476, 5.0000, 3.0000, 3.0952, 2.9474, 3.7727, 2.8636,\n",
      "        5.0000, 3.1364, 3.0000, 3.6364, 3.0000, 4.9545, 4.1818, 5.0000, 3.0000,\n",
      "        3.0000, 3.0000, 5.0000, 4.5000, 5.0000, 4.0909, 3.3636, 3.0000, 3.0833,\n",
      "        3.0000, 3.0000, 4.0909, 3.4091, 3.0000, 5.0000, 3.2273, 5.0000, 3.6364,\n",
      "        3.7727, 5.0000, 3.2857, 2.6364, 2.9545, 5.0000, 3.0000, 3.9545, 3.2609,\n",
      "        3.4762, 3.9545, 5.0000, 3.2857, 3.0000, 5.0000, 3.0000, 3.0909, 3.0000,\n",
      "        2.9545, 3.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/140 [00:26<18:15,  7.99s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs tensor([[ 1.8080e-01],\n",
      "        [ 6.1126e-01],\n",
      "        [ 5.6332e-01],\n",
      "        [ 1.4074e-01],\n",
      "        [-8.8391e-02],\n",
      "        [ 3.5139e-01],\n",
      "        [ 7.8885e-01],\n",
      "        [ 1.0019e-01],\n",
      "        [ 8.9931e-01],\n",
      "        [ 7.3645e-01],\n",
      "        [ 1.6398e+00],\n",
      "        [ 3.0241e-01],\n",
      "        [ 3.3052e-01],\n",
      "        [ 9.9977e-01],\n",
      "        [ 7.6809e-02],\n",
      "        [ 7.2920e-01],\n",
      "        [ 7.2987e-01],\n",
      "        [-5.7421e-02],\n",
      "        [ 7.0311e-01],\n",
      "        [ 3.3227e-01],\n",
      "        [ 7.3163e-01],\n",
      "        [ 1.1937e-01],\n",
      "        [ 8.0072e-01],\n",
      "        [ 4.6366e-01],\n",
      "        [-1.8392e-01],\n",
      "        [ 5.5546e-01],\n",
      "        [ 6.7502e-01],\n",
      "        [ 7.5232e-01],\n",
      "        [ 2.5848e-01],\n",
      "        [-8.5470e-02],\n",
      "        [ 7.2320e-01],\n",
      "        [ 1.8274e-01],\n",
      "        [ 5.9661e-01],\n",
      "        [ 4.4605e-01],\n",
      "        [ 9.3715e-01],\n",
      "        [-4.5075e-01],\n",
      "        [ 1.0019e+00],\n",
      "        [ 4.6461e-01],\n",
      "        [ 4.3441e-02],\n",
      "        [ 1.5008e+00],\n",
      "        [-1.8821e-01],\n",
      "        [ 5.8557e-01],\n",
      "        [ 7.2372e-01],\n",
      "        [ 1.2142e-01],\n",
      "        [ 6.0430e-01],\n",
      "        [ 8.8554e-01],\n",
      "        [ 8.5504e-02],\n",
      "        [ 8.3976e-02],\n",
      "        [ 4.2983e-01],\n",
      "        [-1.6553e-01],\n",
      "        [ 5.0816e-01],\n",
      "        [ 1.4867e-01],\n",
      "        [ 6.4146e-01],\n",
      "        [ 1.3650e+00],\n",
      "        [ 2.6719e-01],\n",
      "        [ 7.7121e-01],\n",
      "        [ 1.1472e+00],\n",
      "        [ 6.8993e-01],\n",
      "        [ 7.2633e-01],\n",
      "        [-6.4505e-02],\n",
      "        [ 6.5084e-01],\n",
      "        [ 3.8084e-01],\n",
      "        [ 6.3668e-01],\n",
      "        [ 6.5423e-01],\n",
      "        [ 5.1998e-01],\n",
      "        [ 1.3008e+00],\n",
      "        [ 4.8304e-01],\n",
      "        [ 1.2879e-01],\n",
      "        [ 9.5879e-01],\n",
      "        [ 2.4355e-01],\n",
      "        [ 4.8266e-01],\n",
      "        [ 5.7265e-01],\n",
      "        [ 1.0059e+00],\n",
      "        [ 1.5015e-01],\n",
      "        [ 8.8227e-02],\n",
      "        [ 2.8144e-01],\n",
      "        [ 4.7546e-01],\n",
      "        [ 9.4864e-01],\n",
      "        [ 6.2953e-01],\n",
      "        [ 5.1971e-01],\n",
      "        [-3.7962e-02],\n",
      "        [ 7.0598e-01],\n",
      "        [ 5.7065e-01],\n",
      "        [ 4.4815e-01],\n",
      "        [ 8.1732e-01],\n",
      "        [ 1.6247e+00],\n",
      "        [-2.2648e-01],\n",
      "        [ 6.8235e-02],\n",
      "        [ 7.5241e-01],\n",
      "        [ 4.5467e-01],\n",
      "        [ 1.2447e+00],\n",
      "        [ 4.6042e-01],\n",
      "        [ 4.7776e-01],\n",
      "        [ 4.4034e-01],\n",
      "        [ 6.6528e-01],\n",
      "        [-1.6026e-03],\n",
      "        [ 3.0189e-01],\n",
      "        [ 6.8669e-01],\n",
      "        [ 8.9403e-01],\n",
      "        [-4.4175e-02],\n",
      "        [-2.1393e-01],\n",
      "        [ 3.9528e-01],\n",
      "        [ 4.9597e-01],\n",
      "        [ 3.2986e-01],\n",
      "        [ 8.6306e-02],\n",
      "        [ 8.2457e-01],\n",
      "        [ 2.3732e-01],\n",
      "        [ 4.5704e-01],\n",
      "        [ 2.6404e-01],\n",
      "        [ 1.6280e-01],\n",
      "        [ 9.1728e-01],\n",
      "        [ 2.0116e-01],\n",
      "        [-7.2300e-03],\n",
      "        [-1.3710e-02],\n",
      "        [ 7.8119e-01],\n",
      "        [ 3.9542e-01],\n",
      "        [ 5.2557e-01],\n",
      "        [ 7.6006e-01],\n",
      "        [ 4.0842e-01],\n",
      "        [ 5.5788e-01],\n",
      "        [ 6.6491e-01],\n",
      "        [ 7.6179e-01],\n",
      "        [-7.7011e-02],\n",
      "        [ 1.0693e+00],\n",
      "        [ 1.0288e-01],\n",
      "        [ 8.9677e-01],\n",
      "        [ 7.8573e-01],\n",
      "        [ 9.2350e-01]], grad_fn=<AddmmBackward0>)\n",
      "loss tensor(11.6938, grad_fn=<MseLossBackward0>)\n",
      "labels tensor([3.2857, 3.0833, 3.0000, 3.2857, 2.9545, 3.4091, 3.6364, 3.4545, 3.1818,\n",
      "        3.0455, 3.3182, 3.2727, 3.0000, 5.0000, 3.0000, 5.0000, 3.2727, 3.0000,\n",
      "        5.0000, 3.0000, 3.3182, 5.0000, 3.3182, 3.3182, 3.0000, 3.0476, 3.3182,\n",
      "        3.5263, 4.4286, 3.2273, 3.0000, 3.0000, 3.0000, 4.3333, 4.0909, 5.0000,\n",
      "        2.9474, 3.0000, 3.7273, 3.2273, 3.0000, 3.0000, 3.0000, 5.0000, 3.0476,\n",
      "        3.0000, 3.0000, 3.0000, 2.9474, 5.0000, 5.0000, 3.8000, 3.0000, 3.0000,\n",
      "        5.0000, 3.0455, 3.3636, 5.0000, 2.9474, 3.0833, 4.6364, 3.2273, 3.0000,\n",
      "        3.7727, 5.0000, 5.0000, 5.0000, 4.4762, 3.3182, 4.9048, 4.3333, 3.7273,\n",
      "        5.0000, 5.0000, 5.0000, 5.0000, 3.6364, 3.2273, 4.9048, 4.0909, 5.0000,\n",
      "        3.0000, 4.1818, 4.8095, 3.0000, 4.0000, 3.0000, 3.0000, 3.6818, 3.2500,\n",
      "        3.2273, 3.0455, 3.0455, 3.1500, 3.0000, 5.0000, 5.0000, 5.0000, 5.0000,\n",
      "        3.2609, 4.4286, 5.0000, 4.7273, 4.2273, 3.0000, 5.0000, 3.2609, 3.0000,\n",
      "        4.9048, 3.0000, 5.0000, 4.2381, 3.3182, 3.0952, 5.0000, 3.7727, 3.0000,\n",
      "        3.0000, 3.9091, 3.0909, 3.6364, 3.6818, 4.0909, 3.0000, 3.0000, 3.0476,\n",
      "        3.9091, 5.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 4/140 [00:32<16:42,  7.37s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs tensor([[ 0.8451],\n",
      "        [ 0.9271],\n",
      "        [-0.1031],\n",
      "        [ 0.1965],\n",
      "        [ 0.3361],\n",
      "        [ 0.8566],\n",
      "        [ 0.4757],\n",
      "        [ 1.3504],\n",
      "        [ 0.4987],\n",
      "        [ 0.1595],\n",
      "        [ 0.8130],\n",
      "        [ 0.8834],\n",
      "        [ 0.4223],\n",
      "        [ 0.9076],\n",
      "        [ 0.3935],\n",
      "        [ 0.9517],\n",
      "        [ 0.4266],\n",
      "        [ 1.4575],\n",
      "        [ 0.1724],\n",
      "        [-0.1858],\n",
      "        [ 0.4128],\n",
      "        [ 0.2447],\n",
      "        [ 1.1511],\n",
      "        [ 0.9801],\n",
      "        [ 0.1746],\n",
      "        [ 0.5792],\n",
      "        [ 0.4875],\n",
      "        [ 1.0066],\n",
      "        [-0.0350],\n",
      "        [ 0.4486],\n",
      "        [ 0.9044],\n",
      "        [ 0.4034],\n",
      "        [ 0.7475],\n",
      "        [-0.1961],\n",
      "        [ 0.2923],\n",
      "        [ 0.5315],\n",
      "        [ 0.2356],\n",
      "        [ 0.7252],\n",
      "        [ 0.9820],\n",
      "        [ 1.6015],\n",
      "        [ 0.7913],\n",
      "        [ 1.4878],\n",
      "        [ 0.6151],\n",
      "        [ 0.0619],\n",
      "        [ 0.6493],\n",
      "        [ 0.5125],\n",
      "        [ 1.2560],\n",
      "        [ 0.7944],\n",
      "        [-0.0332],\n",
      "        [ 0.1418],\n",
      "        [ 0.9646],\n",
      "        [ 0.2344],\n",
      "        [ 0.1456],\n",
      "        [ 0.3502],\n",
      "        [ 0.2035],\n",
      "        [ 0.7509],\n",
      "        [ 0.8902],\n",
      "        [ 0.5908],\n",
      "        [ 0.2387],\n",
      "        [ 0.0859],\n",
      "        [ 0.5475],\n",
      "        [ 0.5794],\n",
      "        [ 0.5363],\n",
      "        [-0.2395],\n",
      "        [ 1.0451],\n",
      "        [ 0.7926],\n",
      "        [ 0.4599],\n",
      "        [ 0.5070],\n",
      "        [ 0.5597],\n",
      "        [ 0.0777],\n",
      "        [-0.3083],\n",
      "        [-0.1322],\n",
      "        [ 0.3199],\n",
      "        [ 1.0022],\n",
      "        [ 0.2079],\n",
      "        [ 0.9940],\n",
      "        [ 0.6579],\n",
      "        [ 0.5083],\n",
      "        [ 0.5574],\n",
      "        [ 0.4893],\n",
      "        [ 0.1738],\n",
      "        [ 0.4835],\n",
      "        [ 0.6205],\n",
      "        [ 0.9874],\n",
      "        [ 0.8593],\n",
      "        [ 0.3675],\n",
      "        [ 0.2891],\n",
      "        [ 1.8260],\n",
      "        [ 0.2357],\n",
      "        [ 0.7461],\n",
      "        [-0.3199],\n",
      "        [ 0.5171],\n",
      "        [ 0.7955],\n",
      "        [ 0.7915],\n",
      "        [ 0.5391],\n",
      "        [ 0.4596],\n",
      "        [ 0.8272],\n",
      "        [ 1.0960],\n",
      "        [ 1.2699],\n",
      "        [ 0.1097],\n",
      "        [ 0.4305],\n",
      "        [ 0.4033],\n",
      "        [ 0.9060],\n",
      "        [ 0.9182],\n",
      "        [ 0.1505],\n",
      "        [ 0.4033],\n",
      "        [ 0.0103],\n",
      "        [-0.1668],\n",
      "        [ 0.2614],\n",
      "        [-0.1660],\n",
      "        [ 0.9301],\n",
      "        [ 1.2679],\n",
      "        [ 0.0058],\n",
      "        [ 0.7279],\n",
      "        [ 0.5527],\n",
      "        [ 0.5623],\n",
      "        [ 0.5086],\n",
      "        [ 0.8215],\n",
      "        [ 0.8729],\n",
      "        [ 0.8574],\n",
      "        [ 0.6431],\n",
      "        [ 0.7861],\n",
      "        [ 0.9774],\n",
      "        [ 0.1138],\n",
      "        [ 0.3940],\n",
      "        [ 0.2120],\n",
      "        [ 0.2094],\n",
      "        [ 0.6017]], grad_fn=<AddmmBackward0>)\n",
      "loss tensor(11.0920, grad_fn=<MseLossBackward0>)\n",
      "labels tensor([5.0000, 3.0909, 5.0000, 3.2857, 3.1500, 3.3000, 4.9048, 3.0455, 2.9545,\n",
      "        3.0000, 3.1905, 5.0000, 3.6818, 3.0000, 3.0000, 3.2609, 5.0000, 3.0000,\n",
      "        5.0000, 3.2857, 4.1364, 3.2273, 3.2273, 3.0000, 3.0455, 3.2609, 2.6364,\n",
      "        5.0000, 5.0000, 5.0000, 3.0000, 3.0000, 3.9091, 3.6364, 5.0000, 5.0000,\n",
      "        3.0000, 5.0000, 5.0000, 3.0000, 3.3182, 3.6364, 4.6364, 4.6364, 4.1364,\n",
      "        3.0000, 3.0455, 5.0000, 3.2273, 3.0000, 5.0000, 3.0000, 3.0000, 3.0000,\n",
      "        5.0000, 3.9091, 5.0000, 5.0000, 3.0000, 3.9545, 3.0455, 5.0000, 3.9545,\n",
      "        5.0000, 3.5263, 3.6818, 3.3182, 3.9545, 3.2273, 3.7143, 5.0000, 5.0000,\n",
      "        3.0000, 5.0000, 3.0000, 3.2609, 3.8000, 3.4286, 5.0000, 5.0000, 3.0000,\n",
      "        3.0000, 3.9545, 3.7727, 5.0000, 3.0000, 4.0000, 3.1429, 3.0000, 2.9524,\n",
      "        3.5263, 4.0000, 3.0000, 3.0952, 5.0000, 5.0000, 3.0952, 3.0909, 3.2727,\n",
      "        3.0000, 4.3333, 5.0000, 3.0000, 5.0000, 3.3182, 3.0000, 3.0000, 3.2273,\n",
      "        3.0000, 3.0000, 3.6818, 5.0000, 5.0000, 4.9048, 5.0000, 3.3636, 5.0000,\n",
      "        3.0000, 5.0000, 3.0000, 2.9545, 5.0000, 5.0000, 3.0909, 3.0476, 5.0000,\n",
      "        4.0909, 3.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 5/140 [00:39<15:52,  7.05s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs tensor([[ 0.6932],\n",
      "        [-0.0207],\n",
      "        [ 0.4903],\n",
      "        [ 0.5259],\n",
      "        [-0.0563],\n",
      "        [ 0.5875],\n",
      "        [ 0.1028],\n",
      "        [ 0.7487],\n",
      "        [ 0.6066],\n",
      "        [ 0.1397],\n",
      "        [ 1.3457],\n",
      "        [ 0.4008],\n",
      "        [ 0.3368],\n",
      "        [ 0.3565],\n",
      "        [ 0.7378],\n",
      "        [ 0.5287],\n",
      "        [ 0.7695],\n",
      "        [ 0.6379],\n",
      "        [ 0.0708],\n",
      "        [ 0.9839],\n",
      "        [ 1.3036],\n",
      "        [ 0.3823],\n",
      "        [ 0.2575],\n",
      "        [ 0.1084],\n",
      "        [ 1.1936],\n",
      "        [ 0.5102],\n",
      "        [ 0.6090],\n",
      "        [ 0.6964],\n",
      "        [ 0.2651],\n",
      "        [ 0.5814],\n",
      "        [ 1.0980],\n",
      "        [ 0.8345],\n",
      "        [ 0.9034],\n",
      "        [ 0.7193],\n",
      "        [ 0.5856],\n",
      "        [ 0.3862],\n",
      "        [ 0.8161],\n",
      "        [ 0.0104],\n",
      "        [ 0.9198],\n",
      "        [ 0.4422],\n",
      "        [-0.3181],\n",
      "        [ 1.0256],\n",
      "        [ 0.5488],\n",
      "        [ 0.9005],\n",
      "        [ 0.8192],\n",
      "        [-0.3550],\n",
      "        [ 0.2327],\n",
      "        [ 0.0900],\n",
      "        [ 0.5271],\n",
      "        [ 0.5507],\n",
      "        [-0.1020],\n",
      "        [ 0.4227],\n",
      "        [ 0.9384],\n",
      "        [ 0.3935],\n",
      "        [ 0.5291],\n",
      "        [ 0.0556],\n",
      "        [ 0.0708],\n",
      "        [ 0.1316],\n",
      "        [ 0.9418],\n",
      "        [ 1.0115],\n",
      "        [ 0.4398],\n",
      "        [ 0.7755],\n",
      "        [ 0.4871],\n",
      "        [ 0.2208],\n",
      "        [ 0.2109],\n",
      "        [ 0.1998],\n",
      "        [ 0.5753],\n",
      "        [ 0.5125],\n",
      "        [ 0.7539],\n",
      "        [ 0.4544],\n",
      "        [ 0.5804],\n",
      "        [ 0.2869],\n",
      "        [ 0.4324],\n",
      "        [ 0.2491],\n",
      "        [ 0.2459],\n",
      "        [ 0.6375],\n",
      "        [ 0.2781],\n",
      "        [ 0.3937],\n",
      "        [ 0.3630],\n",
      "        [ 0.9604],\n",
      "        [ 0.8818],\n",
      "        [ 1.6535],\n",
      "        [ 0.8355],\n",
      "        [ 0.9081],\n",
      "        [ 0.8285],\n",
      "        [ 1.4566],\n",
      "        [ 1.1331],\n",
      "        [-0.1252],\n",
      "        [ 0.3927],\n",
      "        [ 0.7204],\n",
      "        [ 0.5202],\n",
      "        [ 0.2980],\n",
      "        [ 0.8678],\n",
      "        [ 1.2743],\n",
      "        [ 0.5925],\n",
      "        [ 1.4097],\n",
      "        [ 0.9548],\n",
      "        [ 0.6775],\n",
      "        [ 0.4005],\n",
      "        [ 0.5820],\n",
      "        [ 0.3905],\n",
      "        [ 0.2084],\n",
      "        [ 0.5137],\n",
      "        [ 0.4287],\n",
      "        [ 1.0795],\n",
      "        [ 0.1849],\n",
      "        [ 1.3956],\n",
      "        [ 0.6221],\n",
      "        [ 0.8780],\n",
      "        [ 0.3815],\n",
      "        [ 1.0354],\n",
      "        [ 0.4168],\n",
      "        [ 0.8688],\n",
      "        [ 0.8086],\n",
      "        [ 0.8372],\n",
      "        [ 0.6150],\n",
      "        [ 0.7904],\n",
      "        [-0.0088],\n",
      "        [ 0.6159],\n",
      "        [ 0.8561],\n",
      "        [ 0.7729],\n",
      "        [ 1.0908],\n",
      "        [ 0.8677],\n",
      "        [ 0.1803],\n",
      "        [ 0.4738],\n",
      "        [ 0.6881],\n",
      "        [-0.1102],\n",
      "        [ 1.2803]], grad_fn=<AddmmBackward0>)\n",
      "loss tensor(11.3831, grad_fn=<MseLossBackward0>)\n",
      "labels tensor([5.0000, 3.9091, 2.9524, 3.0000, 3.0455, 3.0455, 3.0952, 5.0000, 3.1429,\n",
      "        5.0000, 3.0000, 5.0000, 3.2609, 3.0000, 5.0000, 3.0000, 5.0000, 3.0909,\n",
      "        5.0000, 3.9545, 3.0000, 3.0000, 3.0909, 3.9545, 4.9048, 5.0000, 3.0000,\n",
      "        3.0952, 3.0000, 5.0000, 4.9000, 4.5000, 3.6364, 3.9091, 4.5000, 3.0476,\n",
      "        3.3182, 2.9524, 4.3333, 3.0000, 5.0000, 3.0455, 3.4762, 3.3000, 3.2500,\n",
      "        3.0000, 4.2727, 3.2727, 3.9091, 3.3182, 4.6364, 3.0000, 4.7619, 5.0000,\n",
      "        3.4500, 3.0000, 5.0000, 3.0455, 3.0000, 3.0476, 3.0455, 5.0000, 3.0000,\n",
      "        3.0909, 5.0000, 4.8095, 3.0000, 3.5263, 3.0000, 3.0000, 3.2273, 3.0000,\n",
      "        5.0000, 5.0000, 3.0000, 5.0000, 5.0000, 3.0000, 5.0000, 3.0000, 3.0000,\n",
      "        5.0000, 4.5000, 3.9091, 5.0000, 3.0000, 3.0000, 4.9048, 5.0000, 3.9545,\n",
      "        3.0000, 3.0000, 3.9545, 3.6364, 3.0000, 5.0000, 3.0000, 3.0000, 5.0000,\n",
      "        3.2500, 5.0000, 4.8095, 3.0000, 5.0000, 3.0476, 3.0000, 3.0000, 3.6818,\n",
      "        5.0000, 3.4545, 5.0000, 5.0000, 3.0000, 3.2500, 5.0000, 3.2857, 3.8182,\n",
      "        3.4000, 5.0000, 3.0000, 5.0000, 5.0000, 5.0000, 2.9545, 3.0000, 3.0000,\n",
      "        2.9545, 5.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/140 [00:45<15:28,  6.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs tensor([[ 0.4502],\n",
      "        [ 0.7074],\n",
      "        [ 0.4310],\n",
      "        [ 0.7698],\n",
      "        [ 0.5750],\n",
      "        [ 1.2358],\n",
      "        [ 0.0426],\n",
      "        [ 0.3341],\n",
      "        [ 0.4106],\n",
      "        [ 0.8689],\n",
      "        [ 0.3714],\n",
      "        [ 0.7798],\n",
      "        [ 0.6740],\n",
      "        [ 1.0718],\n",
      "        [ 0.9814],\n",
      "        [ 0.5233],\n",
      "        [-0.3094],\n",
      "        [ 0.3271],\n",
      "        [ 0.7271],\n",
      "        [ 0.7488],\n",
      "        [ 0.0856],\n",
      "        [ 1.1403],\n",
      "        [ 0.1634],\n",
      "        [ 0.9833],\n",
      "        [ 0.2816],\n",
      "        [ 0.6400],\n",
      "        [ 0.3258],\n",
      "        [ 0.7880],\n",
      "        [ 0.3811],\n",
      "        [ 0.0560],\n",
      "        [ 0.9568],\n",
      "        [ 1.0310],\n",
      "        [ 0.5419],\n",
      "        [ 0.8092],\n",
      "        [ 0.8629],\n",
      "        [ 0.7968],\n",
      "        [ 0.8707],\n",
      "        [ 0.6073],\n",
      "        [ 0.9473],\n",
      "        [ 0.1669],\n",
      "        [ 0.7625],\n",
      "        [ 0.9289],\n",
      "        [ 0.7841],\n",
      "        [ 0.5892],\n",
      "        [ 0.3863],\n",
      "        [ 0.5057],\n",
      "        [ 0.6784],\n",
      "        [ 0.6393],\n",
      "        [ 0.8371],\n",
      "        [ 0.7444],\n",
      "        [ 0.8761],\n",
      "        [ 0.5886],\n",
      "        [ 0.1637],\n",
      "        [ 0.3941],\n",
      "        [ 1.2131],\n",
      "        [-0.0083],\n",
      "        [ 1.1009],\n",
      "        [ 0.8456],\n",
      "        [ 1.2500],\n",
      "        [ 1.2320],\n",
      "        [ 0.6884],\n",
      "        [ 0.9276],\n",
      "        [ 0.5246],\n",
      "        [ 0.4656],\n",
      "        [ 0.6469],\n",
      "        [ 0.1941],\n",
      "        [ 0.9921],\n",
      "        [ 0.7957],\n",
      "        [ 1.3275],\n",
      "        [ 0.9064],\n",
      "        [ 0.2942],\n",
      "        [ 0.1598],\n",
      "        [ 0.4964],\n",
      "        [ 0.3881],\n",
      "        [ 0.4054],\n",
      "        [ 0.6637],\n",
      "        [ 0.6863],\n",
      "        [ 0.6636],\n",
      "        [ 1.0526],\n",
      "        [ 0.7927],\n",
      "        [ 0.7605],\n",
      "        [ 1.1476],\n",
      "        [ 0.8945],\n",
      "        [ 1.1929],\n",
      "        [ 0.8158],\n",
      "        [ 1.0898],\n",
      "        [ 0.5822],\n",
      "        [ 0.9131],\n",
      "        [ 0.0044],\n",
      "        [ 0.8300],\n",
      "        [-0.3364],\n",
      "        [ 1.1624],\n",
      "        [ 0.3669],\n",
      "        [ 0.2967],\n",
      "        [ 0.5586],\n",
      "        [ 0.9297],\n",
      "        [ 0.4702],\n",
      "        [ 1.0449],\n",
      "        [ 0.1967],\n",
      "        [ 1.0118],\n",
      "        [ 0.6928],\n",
      "        [ 0.5361],\n",
      "        [ 0.3401],\n",
      "        [ 0.1508],\n",
      "        [ 0.4230],\n",
      "        [ 0.9344],\n",
      "        [ 0.6620],\n",
      "        [ 0.7192],\n",
      "        [ 0.9416],\n",
      "        [ 0.4100],\n",
      "        [ 1.0667],\n",
      "        [ 0.3648],\n",
      "        [ 0.8186],\n",
      "        [ 0.2341],\n",
      "        [-0.1698],\n",
      "        [ 1.5276],\n",
      "        [ 0.5119],\n",
      "        [ 0.5881],\n",
      "        [ 0.8169],\n",
      "        [ 0.4699],\n",
      "        [-0.1068],\n",
      "        [ 0.6304],\n",
      "        [ 0.4150],\n",
      "        [ 0.0730],\n",
      "        [ 0.9798],\n",
      "        [ 0.3108],\n",
      "        [ 0.8276],\n",
      "        [ 0.4011]], grad_fn=<AddmmBackward0>)\n",
      "loss tensor(11.0722, grad_fn=<MseLossBackward0>)\n",
      "labels tensor([2.6364, 4.9545, 3.0000, 5.0000, 5.0000, 3.0000, 3.9545, 3.0000, 3.0909,\n",
      "        3.0909, 3.4091, 3.7273, 3.0909, 5.0000, 4.3333, 3.6364, 5.0000, 5.0000,\n",
      "        3.0000, 3.0952, 5.0000, 5.0000, 5.0000, 3.0000, 5.0000, 5.0000, 4.9048,\n",
      "        5.0000, 5.0000, 5.0000, 3.0000, 3.1429, 2.9545, 3.0000, 3.2500, 3.1500,\n",
      "        3.0000, 3.3182, 5.0000, 5.0000, 3.2727, 2.9545, 5.0000, 5.0000, 3.3182,\n",
      "        3.2857, 3.6364, 4.8095, 3.3182, 3.2857, 3.0000, 3.0000, 3.6364, 5.0000,\n",
      "        3.0000, 3.0000, 3.0000, 3.0476, 3.0000, 3.0000, 3.1364, 3.0000, 3.9091,\n",
      "        3.0909, 4.9048, 5.0000, 3.2857, 4.9545, 4.7273, 3.2273, 3.0000, 3.9091,\n",
      "        3.9545, 4.7273, 4.1364, 3.3182, 5.0000, 3.2500, 5.0000, 3.0000, 4.2727,\n",
      "        4.3333, 3.0952, 4.9048, 5.0000, 5.0000, 3.2273, 5.0000, 5.0000, 3.0000,\n",
      "        5.0000, 5.0000, 5.0000, 3.1429, 5.0000, 4.1429, 3.0000, 5.0000, 3.1905,\n",
      "        2.9545, 3.4762, 3.4091, 3.0000, 3.9091, 3.0000, 3.0000, 4.2381, 3.0000,\n",
      "        4.4762, 5.0000, 4.5000, 3.0000, 5.0000, 3.0000, 3.9091, 4.7273, 3.3636,\n",
      "        5.0000, 3.5263, 3.0000, 5.0000, 5.0000, 3.6364, 3.3182, 5.0000, 3.0000,\n",
      "        5.0000, 3.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/140 [00:48<18:00,  8.06s/batch]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m optimizer_ft \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(params_to_update, lr\u001b[39m=\u001b[39m\u001b[39m1e-4\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[39m# Training a pretrained Resnet18 on a balanced dataset\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m model_ft, val_hist, hist  \u001b[39m=\u001b[39m train_model(model_ft, dataloaders_dict, locations, target_dict,   criterion, optimizer_ft,num_epochs\u001b[39m=\u001b[39;49m epoch)\n",
      "Cell \u001b[1;32mIn[45], line 54\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloaders, locations, target_dict, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39m# forward\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[39m# track history if only in train\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(phase \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     49\u001b[0m     \u001b[39m# Get model outputs and calculate loss\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[39m# Special case for inception because in training it has an auxiliary output. In train\u001b[39;00m\n\u001b[0;32m     51\u001b[0m     \u001b[39m#   mode we calculate the loss by summing the final output and the auxiliary output\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     \u001b[39m#   but in testing we only consider the final output.\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m   outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[0;32m     55\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39moutputs\u001b[39m\u001b[39m'\u001b[39m, outputs)\n\u001b[0;32m     56\u001b[0m   loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    270\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m    271\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n\u001b[1;32m--> 273\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer1(x)\n\u001b[0;32m    274\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\resnet.py:96\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     93\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[0;32m     94\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[1;32m---> 96\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(out)\n\u001b[0;32m     97\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownsample \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# ResNet 34\n",
    "model_ft = models.resnet34(pretrained=True)\n",
    "set_parameter_requires_grad(model_ft, True)\n",
    "model_ft.fc = nn.Linear(512, 1)\n",
    "\n",
    "input_size = 224\n",
    "model_ft_balanced = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(params_to_update, lr=1e-4)\n",
    "\n",
    "# Training a pretrained Resnet18 on a balanced dataset\n",
    "model_ft, val_hist, hist  = train_model(model_ft, dataloaders_dict, locations, target_dict,   criterion, optimizer_ft,num_epochs= epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "130e6d816688b9af188066b9a72040e076a5a747fd0c2aa3cd7565dfdb5c8d2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
