{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9d8e78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting torch\n",
      "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m529.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m599.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Collecting lit\n",
      "  Downloading lit-16.0.0.tar.gz (144 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cmake\n",
      "  Downloading cmake-3.26.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93582 sha256=784674804d03e25edc54cfba1470e343147cb6e76cfa97770fd5fb8bd0c0858e\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e5/7f/66/8bfd6d52625bf85b29fa507f79fbc3f5cb4bb72eae40318074\n",
      "Successfully built lit\n",
      "Installing collected packages: lit, cmake, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "Successfully installed cmake-3.26.1 lit-16.0.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch==2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (2.0.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (1.22.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (10.2.10.91)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.7.4.91)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (10.9.0.58)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (4.4.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (3.9.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch==2.0.0->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchvision) (65.6.3)\n",
      "Requirement already satisfied: lit in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0->torchvision) (16.0.0)\n",
      "Requirement already satisfied: cmake in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.26.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch==2.0.0->torchvision) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch==2.0.0->torchvision) (1.2.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.15.1\n",
      "Success - the MySageMakerInstance is in the eu-west-2 region. You will use the container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.predictor import csv_serializer\n",
    "!pip install torch\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "!pip install torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.models as models\n",
    "import time\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import operator\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "\n",
    "\n",
    "\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbee56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bucket_name = 'trained_models'\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# check if the bucket exists\n",
    "if s3.Bucket(bucket_name) in s3.buckets.all():\n",
    "    print(f\"{bucket_name} already exists.\")\n",
    "else:\n",
    "    # create the bucket\n",
    "    s3.create_bucket(Bucket=bucket_name)\n",
    "    print(f\"{bucket_name} created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfce94c",
   "metadata": {},
   "source": [
    "# Building a dataloader for STREET LEVEL IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "040fbd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "\n",
    "class S3ImageDataset(Dataset):\n",
    "    def __init__(self, bucket_name, folder_path, class_folders=None, transform=None):\n",
    "        # initialize attributes\n",
    "        self.bucket_name = bucket_name\n",
    "        self.folder_path = folder_path\n",
    "        self.class_folders = class_folders\n",
    "        self.transform = transform\n",
    "        \n",
    "        # create S3 resource\n",
    "        self.s3 = boto3.resource('s3')\n",
    "        self.bucket = self.s3.Bucket(bucket_name)\n",
    "        \n",
    "        # initialize lists to store image paths and labels\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        s3 = boto3.client('s3')\n",
    "        \n",
    "        # Make sure the prefix ends with a forward slash\n",
    "        if not folder_path.endswith('/'):\n",
    "            folder_path = folder_path + '/'\n",
    "\n",
    "        # List all folders in the folder\n",
    "        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=folder_path, Delimiter='/')\n",
    "\n",
    "        image_data = []\n",
    "\n",
    "        # Loop through the folders and print their names\n",
    "        for obj in tqdm(response.get('CommonPrefixes', [])):\n",
    "            folder_name = obj.get('Prefix').replace(folder_path, '', 1).strip('/')\n",
    "            full_path = folder_path + folder_name\n",
    "            for sub_obj in s3.list_objects_v2(Bucket=bucket_name, Prefix=full_path)['Contents']:\n",
    "                image_data.append((sub_obj['Key'], folder_name))\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            results = list(tqdm(executor.map(self.load_image, image_data), total=len(image_data)))\n",
    "\n",
    "        for img, label in results:\n",
    "            self.images.append(img)\n",
    "            self.labels.append(label)\n",
    "\n",
    "                \n",
    "    def load_image(self, img_data):\n",
    "        img_obj = self.bucket.Object(img_data[0])\n",
    "        img_data = img_obj.get().get('Body').read()\n",
    "        img = Image.open(BytesIO(img_data))\n",
    "        # apply transformation if specified\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return (img, img_data[1])\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the number of images in the dataset\n",
    "        return len(self.images)\n",
    "\n",
    "class S3DataLoader:\n",
    "    def __init__(self, bucket_name, folder_path, batch_size=32, shuffle=True, num_workers=4, transform=None):\n",
    "        # initialize the dataset and dataloader\n",
    "        self.dataset = S3ImageDataset(bucket_name=bucket_name, folder_path=folder_path, class_folders=None, transform=transform)\n",
    "        self.split_dataset = self.train_val_dataset(self.dataset)\n",
    "        self.split_loader = {x: DataLoader(self.split_dataset[x], batch_size=batch_size, shuffle=shuffle, num_workers=num_workers) for x in ['train', 'val']}\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # return the iterator over the dataloader\n",
    "        return iter(self.split_loader)\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the number of batches in the dataloader\n",
    "        return len(self.split_loader)\n",
    "    \n",
    "    def train_val_dataset(self, val_split=0.3):\n",
    "        # Split the indices of the dataset into train and validation sets\n",
    "        train_idx, val_idx = train_test_split(list(range(len(self.dataset))), test_size=val_split)\n",
    "\n",
    "        # Create a dictionary to store the train and validation datasets\n",
    "        datasets = {}\n",
    "\n",
    "        # Create a Subset for the train dataset using the train indices\n",
    "        datasets['train'] = Subset(self.dataset, train_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec08816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [00:08<00:00, 24.39it/s]\n",
      "  1%|▏         | 254/19382 [00:05<06:53, 46.25it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultimodalrecognition/streetlevel_images/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m---> 10\u001b[0m s3dl \u001b[38;5;241m=\u001b[39m \u001b[43mS3DataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m street_dataloaders_dict \u001b[38;5;241m=\u001b[39m s3dl\u001b[38;5;241m.\u001b[39msplit_loader\n",
      "Cell \u001b[0;32mIn[15], line 72\u001b[0m, in \u001b[0;36mS3DataLoader.__init__\u001b[0;34m(self, bucket_name, folder_path, batch_size, shuffle, num_workers, transform)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, bucket_name, folder_path, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# initialize the dataset and dataloader\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[43mS3ImageDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbucket_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_folders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_val_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_loader \u001b[38;5;241m=\u001b[39m {x: DataLoader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_dataset[x], batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39mshuffle, num_workers\u001b[38;5;241m=\u001b[39mnum_workers) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "Cell \u001b[0;32mIn[15], line 48\u001b[0m, in \u001b[0;36mS3ImageDataset.__init__\u001b[0;34m(self, bucket_name, folder_path, class_folders, transform)\u001b[0m\n\u001b[1;32m     45\u001b[0m         image_data\u001b[38;5;241m.\u001b[39mappend((sub_obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKey\u001b[39m\u001b[38;5;124m'\u001b[39m], folder_name))\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 48\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, label \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39mappend(img)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define data transforms\n",
    "transform = transforms.Compose([transforms.Resize(224),\n",
    "                                transforms.CenterCrop(224),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "# create S3 dataloader\n",
    "bucket_name = \"capgemini-cvguild\"\n",
    "folder_path = \"multimodalrecognition/streetlevel_images/\"\n",
    "batch_size = 32\n",
    "s3dl = S3DataLoader(bucket_name, folder_path, batch_size=batch_size, shuffle=True, num_workers=4, transform = transform)\n",
    "street_dataloaders_dict = s3dl.split_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa92fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Set the bucket name and file name\n",
    "bucket_name = \"capgemini-cvguild\"\n",
    "file_name =  'multimodalrecognition/population_indicators/dhs_final_labels.csv'\n",
    "\n",
    "# Download the file from S3 to a DataFrame\n",
    "obj = s3.get_object(Bucket=bucket_name, Key=file_name)\n",
    "features_df = pd.read_csv(obj['Body'])\n",
    "display(features_df)\n",
    "\n",
    "# make a target dict\n",
    "target_dict = {}\n",
    "test_keys = list(features_df['DHSID_EA'])\n",
    "test_values = list(features_df['sanitation_index'])\n",
    "\n",
    "target_dict = {test_keys[i]: test_values[i] for i in range(len(test_keys))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b0f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def train_model(model, dataloaders, locations, target_dict,  criterion, optimizer,num_epochs=20, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "    train_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        with tqdm(dataloaders[phase],unit = 'batch') as tepoch:\n",
    "            # Iterate over data.\n",
    "            \n",
    "            print(tepoch)\n",
    "            for inputs, labels in tepoch:\n",
    "                # get DHSID_EA id for all labels\n",
    "                lb_ids = [locations[id] for id in labels]\n",
    "                # get feature values\n",
    "                labels = [target_dict[lb_id] for lb_id in lb_ids]\n",
    "\n",
    "                labels = torch.Tensor(labels)\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                print('labels',labels)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    print('outputs', outputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    print('loss', loss)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #getCategoricalAccuracy(preds, labels.data, class_dict)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        # deep copy the model\n",
    "        if phase == 'val' and epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        if phase == 'val':\n",
    "            val_acc_history.append(epoch_acc)\n",
    "        if phase == 'train':\n",
    "            train_acc_history.append(epoch_acc)\n",
    "\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history, train_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea53f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321205a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your PyTorch model as an HDF5 file\n",
    "with h5py.File('baselinemodel.h5', 'w') as f:\n",
    "    for k, v in model.state_dict().items():\n",
    "        f.create_dataset(k, data=v.cpu().numpy())\n",
    "\n",
    "# Upload your HDF5 file to an S3 bucket\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'trained_models'\n",
    "s3.upload_file('baselinemodel.h5', bucket_name, 'baselinemodel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
